{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d7aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3df5fcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 2583 short words. Remaining: 367522\n",
      "Loaded 367522 words. Sample: ['aahed', 'aahing', 'aahs', 'aalii', 'aaliis', 'aals', 'aani', 'aardvark', 'aardvarks', 'aardwolf']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Load and preprocess words_alpha.txt into a list without overwriting existing 'words' below\n",
    "wordlist_path = Path(\"words_alpha.txt\")\n",
    "if not wordlist_path.exists():\n",
    "    raise FileNotFoundError(f\"{wordlist_path!s} not found. Place the file in the notebook working directory.\")\n",
    "\n",
    "with wordlist_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "# Normalize, filter, deduplicate and sort\n",
    "words_alpha = sorted({w.strip().lower() for w in lines if w.strip() and w.strip().isalpha()})\n",
    "original_length = len(words_alpha)\n",
    "# Filter out short words (less than 4 characters)   \n",
    "words_alpha = [w for w in words_alpha if len(w) >= 4]\n",
    "# Report filtering\n",
    "filtered_length = len(words_alpha)\n",
    "print(f\"Filtered out {original_length - filtered_length} short words. Remaining: {filtered_length}\")\n",
    "# Summary\n",
    "print(f\"Loaded {len(words_alpha)} words. Sample: {words_alpha[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609db7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,\n",
       " ['bio',\n",
       "  'chem',\n",
       "  'data',\n",
       "  'deep',\n",
       "  'graph',\n",
       "  'learn',\n",
       "  'learning',\n",
       "  'model',\n",
       "  'net',\n",
       "  'network'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example dictionary (replace with a real word list later)\n",
    "words = [\n",
    "    \"graph\", \"net\", \"network\", \"work\", \"data\", \"science\", \"model\", \"learn\", \"learning\",\n",
    "    \"deep\", \"bio\", \"chem\", \"quantum\"\n",
    "]\n",
    "\n",
    "# Common preprocessing: lowercase and unique\n",
    "words = sorted(set(w.strip().lower() for w in words if w.strip()))\n",
    "len(words), words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AhoCorasick:\n",
    "    def __init__(self):\n",
    "        self.next = [dict()]\n",
    "        self.fail = [0]\n",
    "        self.out = [[]]\n",
    "        self.words = []\n",
    "    \n",
    "    def add_word(self, word, index):\n",
    "        word_id = len(self.words)\n",
    "        self.words.append(word)\n",
    "        \n",
    "        state = 0\n",
    "        for ch in word:\n",
    "            nxt = self.next[state].get(ch)\n",
    "            if nxt is None:\n",
    "                nxt = len(self.next)\n",
    "                self.next[state][ch] = nxt\n",
    "                self.next.append({})\n",
    "                self.fail.append(0)\n",
    "                self.out.append([])\n",
    "            state=nxt\n",
    "        self.out[state].append(word_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ahocorasick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
